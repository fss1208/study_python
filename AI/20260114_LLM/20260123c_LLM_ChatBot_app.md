# app.py 코드 설명

이 프로그램은 **사용자가 업로드한 PDF 문서의 내용을 바탕으로 대화를 나눌 수 있는 인공지능 챗봇 애플리케이션**입니다. 

주요 기술 스택으로는 **Streamlit**(웹 UI), **LangChain**(AI 워크플로우), **OpenAI**(LLM 및 임베딩), **FAISS**(벡터 저장소)가 사용되었습니다.

---

### 주요 기능 및 코드 구조

#### 1. 환경 설정 및 라이브러리 로드 (1~16행)
*   **라이브러리**: PDF 읽기(`PyPDF2`), 텍스트 분할(`RecursiveCharacterTextSplitter`), 벡터 검색(`FAISS`), OpenAI 연동 기능을 가져옵니다.
*   **API KEY**: `.env` 파일에서 OpenAI API 키를 읽어와 인증을 처리합니다.

#### 2. PDF 텍스트 추출 (`get_pdf_text`) (18~25행)
*   업로드된 여러 개의 PDF 파일에서 텍스트 데이터를 모두 추출하여 하나의 문자열로 합칩니다.

#### 3. 텍스트 청크(Chunk) 분할 (`get_text_chunks`) (27~36행)
*   추출된 전체 텍스트를 AI가 처리하기 적당한 크기(1,000자 단위)로 자릅니다.
*   문맥이 끊기지 않도록 이전 청크와 200자 정도 겹치게(overlap) 설정되어 있습니다.

#### 4. 벡터 저장소 생성 (`get_vectorstore`) (38~42행)
*   OpenAI의 임베딩 모델(`text-embedding-ada-002`)을 사용하여 텍스트 청크를 숫자로 변환(벡터화)합니다.
*   변환된 데이터를 **FAISS**라는 효율적인 라이브러리를 통해 검색 가능한 데이터베이스 형태로 저장합니다.

#### 5. 대화 체인 구성 (`get_conversation_chain`) (44~53행)
*   **LLM**: `gpt-4.1-mini` 모델을 사용하여 답변을 생성합니다.
*   **Memory**: 이전 대화 내용을 기억하기 위해 `ConversationBufferWindowMemory`를 설정합니다.
*   **Retrieval**: 사용자의 질문과 관련된 문서 내용을 로컬 벡터 저장소에서 찾아와 답변을 생성하는 체인을 만듭니다.

#### 6. Streamlit 사용자 인터페이스 (55~79행)
*   **파일 업로드**: 사용자가 PDF 파일을 올리고 "Upload" 버튼을 누르면 전처리 과정(텍스트 추출 -> 분할 -> 벡터화)이 진행됩니다.
*   **세션 상태 유지**: 생성된 대화 체인은 `st.session_state`에 저장되어 대화가 유지됩니다.
*   **채팅 입력**: 사용자가 질문을 입력하면, 업로드된 문서에서 관련 내용을 찾아 대답해 줍니다.

---

### 프로그램 흐름 (RAG 워크플로우)
1.  **PDF 업로드**: 사용자가 분석할 문서를 제공합니다.
2.  **텍스트 처리**: PDF에서 텍스트를 읽고 작은 단위로 분할합니다.
3.  **임베딩 및 저장**: 텍스트를 벡터로 변환하여 FAISS DB에 저장합니다.
4.  **검색 및 답변(RAG)**: 사용자의 질문과 관련된 텍스트를 DB에서 찾아 LLM이 답변을 생성합니다.

이 방식은 AI가 학습하지 않은 외부 데이터를 활용하여 정확한 답변을 제공하는 **RAG(Retrieval-Augmented Generation)** 기술의 전형적인 구현 사례입니다.
